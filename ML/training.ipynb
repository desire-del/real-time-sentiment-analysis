{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\souss\\Document\\realtime-sentiment-analysis\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\souss\\Document\\realtime-sentiment-analysis\\env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from datasets import load_dataset\n",
    "from torchinfo import summary\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\souss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "type(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE: 32\n",
      "BF16: True\n",
      "DATA_PATH: ../DATA/train.csv\n",
      "EPOCHS: 10\n",
      "EVAL_STRATEGY: epoch\n",
      "LEARNING_RATE: 0.001\n",
      "LOG_DIR: ./logs\n",
      "LOWERCASE: True\n",
      "MAX_SEQ_LEN: 512\n",
      "MODEL_ID: answerdotai/ModernBERT-base\n",
      "MODEL_SAVE_PATH: ./models/tweet_classifier.pt\n",
      "NUM_TRAIN_EPOCHS: 3\n",
      "OPTIMIZER: adamw_torch_fused\n",
      "OUTPUT_DIR: ./training_dir\n",
      "REMOVE_STOPWORDS: True\n",
      "REPORT_TO: tensorboard\n",
      "SAVE_DATA_PATH: ../DATA/train_cleaned.csv\n",
      "SAVE_STRATEGY: epoch\n",
      "USE_CUDA: True\n"
     ]
    }
   ],
   "source": [
    "class Sentiment:\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "class Config:\n",
    "    \"\"\"\n",
    "    Classe statique de configuration pour le mod√®le de classification des tweets.\n",
    "    \"\"\"\n",
    "    # Param√®tres de donn√©es\n",
    "    DATA_PATH = \"../DATA/train.csv\"  \n",
    "    SAVE_DATA_PATH = \"../DATA/train_cleaned.csv\" \n",
    "    MAX_SEQ_LEN = 512              # Longueur maximale des s√©quences\n",
    "    \n",
    "\n",
    "    # Param√®tres de pr√©traitement\n",
    "    REMOVE_STOPWORDS = True         # Indiquer si on enl√®ve les stopwords\n",
    "    LOWERCASE = True                # Mettre tout en minuscules\n",
    "\n",
    "    # Modele ModernBert\n",
    "    MODEL_ID = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "    # Param√®tres d'entra√Ænement\n",
    "    OUTPUT_DIR = \"./training_dir\"    # R√©pertoire de sauvegarde des mod√®les\n",
    "    BATCH_SIZE = 32                 # Taille des batchs\n",
    "    EPOCHS = 10                     # Nombre d'√©poques\n",
    "    LEARNING_RATE = 1e-3            # Taux d'apprentissage\n",
    "    OPTIMIZER = \"adamw_torch_fused\"              # Optimiseur\n",
    "    REPORT_TO  = \"tensorboard\"      # Rapport pour tensorboard\n",
    "    BF16 = True                   # Utiliser le format BF16\n",
    "    NUM_TRAIN_EPOCHS = 3            # Nombre d'√©poques d'entra√Ænement\n",
    "    EVAL_STRATEGY = \"epoch\"         # Strat√©gie d'√©valuation\n",
    "    SAVE_STRATEGY = \"epoch\"         # Strat√©gie de sauvegarde\n",
    "    \n",
    "    \n",
    "\n",
    "    # Param√®tres de sauvegarde\n",
    "    MODEL_SAVE_PATH = \"./models/tweet_classifier.pt\"  # Chemin pour sauvegarder le mod√®le\n",
    "    LOG_DIR = \"./logs\"                                # R√©pertoire des logs\n",
    "\n",
    "    # Utilisation de GPU\n",
    "    USE_CUDA = True               \n",
    "\n",
    "    @staticmethod\n",
    "    def display():\n",
    "        \"\"\"\n",
    "        Affiche les param√®tres de configuration.\n",
    "        \"\"\"\n",
    "        for attr in dir(Config):\n",
    "            if not attr.startswith(\"__\") and not callable(getattr(Config, attr)):\n",
    "                print(f\"{attr}: {getattr(Config, attr)}\")\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "Config.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.USE_CUDA and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"GPU is available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('We are very happy to show you the ü§ó Transformers library.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.text_classification.TextClassificationPipeline"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disnleyland ISN'T tha happiest place in tha wo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMG BELLLLYYY SHOUTIN AT SUM FOOD.. BRB SOOOO ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm still waiting to find out what #caca stand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So's your face</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So sad to see her drive away  wat do i do now??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Disnleyland ISN'T tha happiest place in tha wo...       4\n",
       "1  OMG BELLLLYYY SHOUTIN AT SUM FOOD.. BRB SOOOO ...       0\n",
       "2  I'm still waiting to find out what #caca stand...       0\n",
       "3                                    So's your face        4\n",
       "4    So sad to see her drive away  wat do i do now??       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = pd.read_csv(Config.DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disnleyland ISN'T tha happiest place in tha wo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMG BELLLLYYY SHOUTIN AT SUM FOOD.. BRB SOOOO ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm still waiting to find out what #caca stand...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So's your face</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So sad to see her drive away  wat do i do now??</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    target\n",
       "0  Disnleyland ISN'T tha happiest place in tha wo...  POSITIVE\n",
       "1  OMG BELLLLYYY SHOUTIN AT SUM FOOD.. BRB SOOOO ...  NEGATIVE\n",
       "2  I'm still waiting to find out what #caca stand...  NEGATIVE\n",
       "3                                    So's your face   POSITIVE\n",
       "4    So sad to see her drive away  wat do i do now??  NEGATIVE"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target = df.target.map({0:Sentiment.NEGATIVE, 2:Sentiment.NEUTRAL, 4:Sentiment.POSITIVE})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(9812)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1110188, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='target'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.target.value_counts().plot(kind=\"bar\", color=[\"red\", \"orange\", \"green\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.text, df.target, test_size=0.002, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_preds = classifier(X_test.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score = [pred['score'] if pred['label'].startswith('P') else 1-pred['score']  for pred in prob_preds ]\n",
    "pred_sentiment = [pred['label'] for pred in prob_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:        \n",
    "        label = Sentiment.NEUTRAL\n",
    "        if score <= Sentiment.SENTIMENT_THRESHOLDS[0]:\n",
    "            label = Sentiment.NEGATIVE\n",
    "        elif score >= Sentiment.SENTIMENT_THRESHOLDS[1]:\n",
    "            label = Sentiment.POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return Sentiment.NEGATIVE if score < 0.5 else Sentiment.POSITIVE\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)# remove urls\n",
    "    tweet = re.sub(r'\\@\\w+|\\#', '', tweet) # remove mentions and hashtags\n",
    "    tweet = re.sub(r'\\d+', '', tweet) # remove numbers\n",
    "    tweet = re.sub(r'<.*?>', '', tweet) # remove html tags\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet) # remove punctuation\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet) # remove extra spaces\n",
    "    tweet = tweet.strip() # remove leading and trailing white spaces\n",
    "    return tweet\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    tweet = clean_tweet(tweet)\n",
    "    tokens = tweet.split()\n",
    "    if Config.REMOVE_STOPWORDS:\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39msum(\u001b[43my_test\u001b[49m\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m==\u001b[39m pred_sentiment)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "np.sum(y_test.values == pred_sentiment)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, pred_sentiment, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE, Sentiment.NEUTRAL])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE, Sentiment.NEUTRAL])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_sentiment, target_names=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disnleyland ISN'T tha happiest place in tha wo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>disnleyland isnt tha happiest place tha world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMG BELLLLYYY SHOUTIN AT SUM FOOD.. BRB SOOOO ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>omg bellllyyy shoutin sum food brb soooo starv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm still waiting to find out what #caca stand...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>im still waiting find caca stands hoping think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So's your face</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>sos face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So sad to see her drive away  wat do i do now??</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>sad see drive away wat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    target  \\\n",
       "0  Disnleyland ISN'T tha happiest place in tha wo...  POSITIVE   \n",
       "1  OMG BELLLLYYY SHOUTIN AT SUM FOOD.. BRB SOOOO ...  NEGATIVE   \n",
       "2  I'm still waiting to find out what #caca stand...  NEGATIVE   \n",
       "3                                    So's your face   POSITIVE   \n",
       "4    So sad to see her drive away  wat do i do now??  NEGATIVE   \n",
       "\n",
       "                                        text_process  \n",
       "0  disnleyland isnt tha happiest place tha world ...  \n",
       "1  omg bellllyyy shoutin sum food brb soooo starv...  \n",
       "2  im still waiting find caca stands hoping think...  \n",
       "3                                           sos face  \n",
       "4                             sad see drive away wat  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_process\"] = df.text.apply(process_tweet)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>disnleyland isnt tha happiest place tha world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>omg bellllyyy shoutin sum food brb soooo starv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>im still waiting find caca stands hoping think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>sos face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>sad see drive away wat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                       text_process\n",
       "0  POSITIVE  disnleyland isnt tha happiest place tha world ...\n",
       "1  NEGATIVE  omg bellllyyy shoutin sum food brb soooo starv...\n",
       "2  NEGATIVE  im still waiting find caca stands hoping think...\n",
       "3  POSITIVE                                           sos face\n",
       "4  NEGATIVE                             sad see drive away wat"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=[\"text\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>disnleyland isnt tha happiest place tha world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>omg bellllyyy shoutin sum food brb soooo starv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>im still waiting find caca stands hoping think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>sos face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>sad see drive away wat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels                                           sentence\n",
       "0  POSITIVE  disnleyland isnt tha happiest place tha world ...\n",
       "1  NEGATIVE  omg bellllyyy shoutin sum food brb soooo starv...\n",
       "2  NEGATIVE  im still waiting find caca stands hoping think...\n",
       "3  POSITIVE                                           sos face\n",
       "4  NEGATIVE                             sad see drive away wat"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns  = ['labels', \"sentence\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels      object\n",
       "sentence    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels      object\n",
       "sentence    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentence\"] = df[\"sentence\"].astype(str)\n",
    "df[\"labels\"] = df[\"labels\"].astype(str)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4887)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.sentence==\"\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1105301, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentence.replace(\"\", np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.sentence==\"\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(Config.SAVE_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'sentence'],\n",
       "        num_rows: 1105301\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset('csv', data_files=Config.SAVE_DATA_PATH)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'sentence'],\n",
       "        num_rows: 994770\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'sentence'],\n",
       "        num_rows: 110531\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_data = data[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "train_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='answerdotai/ModernBERT-base', vocab_size=50280, model_max_length=8192, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"|||IP_ADDRESS|||\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t1: AddedToken(\"<|padding|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50254: AddedToken(\"                        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50255: AddedToken(\"                       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50256: AddedToken(\"                      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50257: AddedToken(\"                     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50258: AddedToken(\"                    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50259: AddedToken(\"                   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50260: AddedToken(\"                  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50261: AddedToken(\"                 \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50262: AddedToken(\"                \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50263: AddedToken(\"               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50264: AddedToken(\"              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50265: AddedToken(\"             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50266: AddedToken(\"            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50267: AddedToken(\"           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50268: AddedToken(\"          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50269: AddedToken(\"         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50270: AddedToken(\"        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50271: AddedToken(\"       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50272: AddedToken(\"      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50273: AddedToken(\"     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50274: AddedToken(\"    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50275: AddedToken(\"   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50276: AddedToken(\"  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50277: AddedToken(\"|||EMAIL_ADDRESS|||\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50278: AddedToken(\"|||PHONE_NUMBER|||\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50279: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50280: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50281: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50282: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50283: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50284: AddedToken(\"[MASK]\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "\t50285: AddedToken(\"[unused0]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50286: AddedToken(\"[unused1]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50287: AddedToken(\"[unused2]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50288: AddedToken(\"[unused3]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50289: AddedToken(\"[unused4]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50290: AddedToken(\"[unused5]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50291: AddedToken(\"[unused6]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50292: AddedToken(\"[unused7]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50293: AddedToken(\"[unused8]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50294: AddedToken(\"[unused9]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50295: AddedToken(\"[unused10]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50296: AddedToken(\"[unused11]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50297: AddedToken(\"[unused12]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50298: AddedToken(\"[unused13]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50299: AddedToken(\"[unused14]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50300: AddedToken(\"[unused15]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50301: AddedToken(\"[unused16]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50302: AddedToken(\"[unused17]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50303: AddedToken(\"[unused18]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50304: AddedToken(\"[unused19]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50305: AddedToken(\"[unused20]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50306: AddedToken(\"[unused21]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50307: AddedToken(\"[unused22]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50308: AddedToken(\"[unused23]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50309: AddedToken(\"[unused24]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50310: AddedToken(\"[unused25]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50311: AddedToken(\"[unused26]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50312: AddedToken(\"[unused27]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50313: AddedToken(\"[unused28]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50314: AddedToken(\"[unused29]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50315: AddedToken(\"[unused30]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50316: AddedToken(\"[unused31]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50317: AddedToken(\"[unused32]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50318: AddedToken(\"[unused33]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50319: AddedToken(\"[unused34]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50320: AddedToken(\"[unused35]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50321: AddedToken(\"[unused36]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50322: AddedToken(\"[unused37]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50323: AddedToken(\"[unused38]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50324: AddedToken(\"[unused39]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50325: AddedToken(\"[unused40]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50326: AddedToken(\"[unused41]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50327: AddedToken(\"[unused42]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50328: AddedToken(\"[unused43]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50329: AddedToken(\"[unused44]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50330: AddedToken(\"[unused45]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50331: AddedToken(\"[unused46]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50332: AddedToken(\"[unused47]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50333: AddedToken(\"[unused48]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50334: AddedToken(\"[unused49]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50335: AddedToken(\"[unused50]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50336: AddedToken(\"[unused51]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50337: AddedToken(\"[unused52]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50338: AddedToken(\"[unused53]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50339: AddedToken(\"[unused54]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50340: AddedToken(\"[unused55]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50341: AddedToken(\"[unused56]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50342: AddedToken(\"[unused57]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50343: AddedToken(\"[unused58]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50344: AddedToken(\"[unused59]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50345: AddedToken(\"[unused60]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50346: AddedToken(\"[unused61]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50347: AddedToken(\"[unused62]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50348: AddedToken(\"[unused63]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50349: AddedToken(\"[unused64]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50350: AddedToken(\"[unused65]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50351: AddedToken(\"[unused66]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50352: AddedToken(\"[unused67]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50353: AddedToken(\"[unused68]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50354: AddedToken(\"[unused69]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50355: AddedToken(\"[unused70]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50356: AddedToken(\"[unused71]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50357: AddedToken(\"[unused72]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50358: AddedToken(\"[unused73]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50359: AddedToken(\"[unused74]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50360: AddedToken(\"[unused75]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50361: AddedToken(\"[unused76]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50362: AddedToken(\"[unused77]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50363: AddedToken(\"[unused78]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50364: AddedToken(\"[unused79]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50365: AddedToken(\"[unused80]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50366: AddedToken(\"[unused81]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50367: AddedToken(\"[unused82]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_ID)\n",
    "tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_max_length = Config.MAX_SEQ_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [50281, 1231, 403, 1077, 5211, 281, 921, 368, 253, 22692, 99, 234, 34717, 398, 6335, 15, 50282], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenizer(\"We are very happy to show you the ü§ó Transformers library.\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"sentence\"],padding=\"max_length\", truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'sentence']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_data[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_test_data[\"train\"][0][\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 994770/994770 [03:28<00:00, 4777.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = train_test_data.map(tokenize, batched=True, remove_columns=[\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['labels', 'input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"].features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 'NEGATIVE',\n",
       " 'input_ids': [50281,\n",
       "  1452,\n",
       "  1578,\n",
       "  36876,\n",
       "  653,\n",
       "  9289,\n",
       "  2372,\n",
       "  5075,\n",
       "  50282,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283,\n",
       "  50283],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"test\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(dtype='string', id=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = tokenized_dataset[\"train\"].features[\"labels\"]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model labels - useful for inference\n",
    "labels = [\"NEGATIVE\",\"POSITIVE\"]\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(Config.MODEL_ID, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "ModernBertForSequenceClassification                          --\n",
       "‚îú‚îÄModernBertModel: 1-1                                       --\n",
       "‚îÇ    ‚îî‚îÄModernBertEmbeddings: 2-1                             --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-1                                   38,682,624\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-2                                   768\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-3                                     --\n",
       "‚îÇ    ‚îî‚îÄModuleList: 2-2                                       --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-4                      5,014,272\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-5                      5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-6                      5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-7                      5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-8                      5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-9                      5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-10                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-11                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-12                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-13                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-14                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-15                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-16                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-17                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-18                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-19                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-20                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-21                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-22                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-23                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-24                     5,015,040\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModernBertEncoderLayer: 3-25                     5,015,040\n",
       "‚îÇ    ‚îî‚îÄLayerNorm: 2-3                                        768\n",
       "‚îú‚îÄModernBertPredictionHead: 1-2                              --\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-4                                           589,824\n",
       "‚îÇ    ‚îî‚îÄGELUActivation: 2-5                                   --\n",
       "‚îÇ    ‚îî‚îÄLayerNorm: 2-6                                        768\n",
       "‚îú‚îÄDropout: 1-3                                               --\n",
       "‚îú‚îÄLinear: 1-4                                                1,538\n",
       "=====================================================================================\n",
       "Total params: 149,606,402\n",
       "Trainable params: 149,606,402\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=Config.OUTPUT_DIR,\n",
    "    num_train_epochs=Config.EPOCHS,\n",
    "    per_device_train_batch_size=Config.BATCH_SIZE,\n",
    "    per_device_eval_batch_size=Config.BATCH_SIZE,\n",
    "    eval_strategy=Config.EVAL_STRATEGY,\n",
    "    save_strategy=Config.SAVE_STRATEGY,\n",
    "    optim=Config.OPTIMIZER,\n",
    "    report_to=Config.REPORT_TO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits_and_labels):\n",
    "    logits, labels = logits_and_labels\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'recall': recall_score(labels, predictions, average='macro'),\n",
    "        'precision': precision_score(labels, predictions, average='macro'),\n",
    "        'f1': f1_score(labels, predictions, average='macro')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\souss\\Document\\realtime-sentiment-analysis\\env\\Lib\\site-packages\\transformers\\trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\souss\\Document\\realtime-sentiment-analysis\\env\\Lib\\site-packages\\transformers\\trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2529\u001b[0m )\n\u001b[0;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2537\u001b[0m ):\n\u001b[0;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\souss\\Document\\realtime-sentiment-analysis\\env\\Lib\\site-packages\\transformers\\trainer.py:3676\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3674\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m   3675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_accepts_loss_kwargs:\n\u001b[1;32m-> 3676\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3677\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3678\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs, num_items_in_batch\u001b[38;5;241m=\u001b[39mnum_items_in_batch)\n",
      "File \u001b[1;32mc:\\Users\\souss\\Document\\realtime-sentiment-analysis\\env\\Lib\\site-packages\\transformers\\trainer.py:3755\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3753\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3754\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m-> 3755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3756\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3757\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(outputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. For reference, the inputs it received are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3758\u001b[0m         )\n\u001b[0;32m   3759\u001b[0m     \u001b[38;5;66;03m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[0;32m   3760\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
